# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

---
## Ответ

Для органищзации проекта с микросервисной архитектурой я основываясь на изученных материалах курса и изучения стороннх ресурсов, предлагаю решение основанно на 
инструменах :

Gitlab CI для организации процессов сборки, включая сборку Docker-образа;

ArgoCD для деплоя приложений;

Vault для безопасного хранения и использования секретов, интегрированного на уровне Gitlab CI.

Преимущества  подхода Gitlab CI:
Унификация процессов. Использование шаблонов позволяет обеспечить единообразие процессов CI/CD для всех проектов. Это особенно важно для крупных организаций с большим количеством проектов.

Повторное использование. Шаблоны могут быть использованы в разных проектах, что сокращает время на настройку CI/CD и минимизирует вероятность ошибок.

Гибкость. При необходимости шаблоны можно модифицировать для определённых проектов, сохраняя при этом общую структуру.

Облегчение управления изменениями. Все изменения в пайплайнах можно вносить централизованно, в репозитории с шаблонами. Это упрощает поддержку и обновление CI/CD процессов для всех проектов одновременно.

Преимущества ArgoCD:

GitOps-ориентированный деплой. ArgoCD автоматически синхронизирует состояние приложения в кластере с его состоянием в репозитории Git. Это делает деплой полностью управляемым через Git, улучшая контроль версий и прозрачность процессов.

Автоматическая синхронизация. ArgoCD непрерывно следит за изменениями в репозитории и автоматически обновляет Kubernetes-кластер, когда изменения происходят.

Гибкость и поддержка различных инструментов. ArgoCD поддерживает деплой из Helm-чартов, Kustomize, Jsonnet и других методов описания инфраструктуры.

Простота визуализации и управления. Встроенная панель управления (Web UI) позволяет легко следить за состоянием всех приложений, их версиями и статусами синхронизации.


Преимущества Vault:

Централизованное управление секретами. Vault предоставляет единое место для безопасного хранения секретов (пароли, токены, API-ключи и другие конфиденциальные данные), что упрощает управление ими.

Динамическая генерация секретов. Vault может динамически генерировать временные доступы, такие как креды для баз данных или облачных сервисов, которые автоматически истекают через определенное время.

Гибкие политики доступа. Политики позволяют настроить гибкий контроль над доступом к секретам на основе ролей и сервисов.

Аудит и безопасность. Vault ведёт полный аудит использования секретов, что помогает отслеживать и контролировать доступ к конфиденциальным данным.

Шифрование данных в движении и покое. Все секреты в Vault хранятся в зашифрованном виде, что обеспечивает высокий уровень безопасности.

Интеграция инструментов, таких как GitLab CI, Kaniko, ArgoCD и HashiCorp Vault, позволяет создавать мощные и безопасные пайплайны, которые обеспечивают стабильность и предсказуемость процесса разработки.

За онову взято обучение, и статья https://habr.com/ru/companies/nixys/articles/841174/

---

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

---
## Ответ
Для данного решения вижу для себя в текущих реалиях только один вариант:
ELK (ElasticSearch, Logstash, Kibana)
ELK – это комбинация из трех отдельных сервисов. Все они с открытым исходным кодом и разработаны одной и той же командой.

В комплекс входят следующие:

Elasticsearch — очень мощная и масштабируемая поисковая инструмент, которая может хранить большие объемы данных и использоваться в качестве кластера.
Logstash — этот компонент используется для получения данных из/в определенное место. Поставляется с широким спектром плагинов и большим сообществом пользователей.
Kibana — это графический интерфейс, который ищет, анализирует и визуализирует большие объемы сложных данных из базы данных Elasticsearch.
Одна из самых функциональных систем с открытым исходным кодом.

Плюсы решения:
Масштабируемость – кластер Elasticsearch (ES) расширяется «на лету» добавлением новых серверов. При этом распределение нагрузки по узлам происходит автоматически.

Отказоустойчивость — в случае сбоя кластерных узлов данные не потеряются, а будут перераспределены, и поисковая система сама продолжит работу. 
Операционная стабильность достигается ведением логов на каждое изменение данных в хранилище сразу на нескольких узлах кластера.
Гибкость поисковых фильтров, включая нечеткий поиск, возможности работы с восточными языками (китайский, японский, корейский) и мультиарендность, когда в рамках одного объекта ES можно динамически организовать несколько различных поисковых систем. 
Благодаря наличию встроенных анализаторов текста Elasticsearch автоматически выполняет токенизацию, лемматизацию, стемминг и прочие преобразования текста для решения NLP-задач, связанных с поиском данных.
Управляемость ES по HTTP с помощью JSON-запросов за счет REST API и визуального веб-интерфейса Kibana.

Универсальность – Logsatsh в потоковом режиме работает одновременно со множеством разных источников данных (СУБД, файлы, системные логи, веб-приложения и пр.), фильтруя и преобразуя их для отправки в хранилище ES. А
NoSQL-природа Elasticsearch (отсутствие схемы) позволяет загружать в него JSON-объекты, которые автоматически индексируются и добавляются в базу поиска. Это позволяет ускорить прототипирование поисковых Big Data решений.

---

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

---
## Ответ
Для организации мониторинга я бы остановился на класическом подходе 
Prometheus + Grafana

Обзор решения
Основной компонент — Prometheus. Prometheus получает метрики из разных сервисов и собирает их в одном месте.

Node exporter — небольшое приложение, собирающее метрики операционной системы и предоставляющее к ним доступ по HTTP. Prometheus собирает данные с одного или нескольких экземпляров Node Exporter.

Grafana — это вишенка на торте. Grafana отображает данные из Prometheus в виде графиков и диаграмм, организованных в дашборды.

---

